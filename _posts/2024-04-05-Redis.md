---
title: "Redis "
date: 2024-04-05
tags:
  - 케이뱅크
  - Redis
  - 주식서비스
  - 개발
category: 실무경험
---
현재 비상장주식 데이터는 매일 19시에 갱신. 그 후로는 변동사항 없음(현재는 24시간에 한번씩 갱신)
ex) 오늘 19시 기준 6600개 종목의 전일기준가격,전일최대최소가격,시총,이전90일 가격리스트그래프 등
데이터 집계,조회 기준이 특정 시점 스냅샷으로 고정되기 때문에 상대적으로 변동정보가 적어 모두 인메모리로 올릴 수 있음.

- 상세종목 조회
  - 극단적으로 90일어치의 데이터(3달간의 가격 리스트)를 Select 해와야 하고 해당 종목 데이터는 총 6600건 정도. 
    - ⇒ 대략 일 6만건 정도
- 순위 조회
  - 조회수,기준가,시가총액 기준으로 Top100개 종목 순위 리스트를 리턴함. 300건 정도
- 기준일시
  - 매일 19시를 기준일로 함. 현재 기준 스냅샷 정보를 활용하기 위해
  - select 종목명,종목코드,기준가격,시총 ~~ from 가격테이블 where 기준일시 = (select max(기준일시) from 가격테이블) 이런식으로 쿼리를 씀
  - maxdate를 쿼리에서 서브쿼리로 호출하지 말고 자바코드에서 따로 호출 후 캐싱함.
  - 이점 : (현재는 데이터가 얼마안되어서 tasklet이지만 조만간 바꿀수도) 데이터가 많아져서 chunk로 수행하는 경우 select max(기준일시) 수행 시 아직 다 적재가 되지않았는데 기준일시를 다음날로 넘김. 그것 기준으로 가격 테이블에서 가격정보를 가져오면 반만 가져올 수도 있음.
  - 캐싱을 수행한 후 배치에서 redis flush를 수행하면 캐시를 바라보다가 적재 step 끝나고 commit 후 캐시를 날리면서 자연스럽게 일자전환 가능
    - +) 나중에 일자전환 후 캐시 날리고 나서 트래픽 문제가 생기면 기준일시 flush 하기 전에 다음날짜 내용을 미리 적재해놓고 기준일시 key만 flush 해버리면 됨
- 특정 종목을 관심등록 해놓은 사람들의 수
  - 고객이 늘어남에 따라 고객아이디,종목코드번호 쌍의 테이블이 많아짐. unique 인덱싱 해놓음
  - 캐싱 key는 종목코드번호 6자리, 조회 연산 수행하는 순간 캐시미스나면 캐싱. 
  - 누군가가 해당 종목코드를 관심 등록/해제하면 캐시 날림
  - 이렇게 한 이유는 조회가 압도적으로 많을 것이기 때문(메인페이지 리스트 각 노드에도 관심여부 필요, 상세조회에도 관심여부 필요….등등)
- 비상장주식 검색 기록 
  - 집계는 매일 19시 마감치고 전일 19시~ 지금까지 검색기록 집계해서 리스트 매김. 이 리스트는 다음날 19시까지 바뀌지 않기 때문에 캐싱하기로 함.
⇒ Locust로 쏘면서 배치로 일자전환 타는것까지 검증완료
