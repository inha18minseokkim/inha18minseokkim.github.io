---
title: "Charset 인코딩 문제, 유량제어 문제"
date: 2024-07-16
tags: [미지정]
category: 기타
---
KAFKA - API 표준 잡는 중

일단 api  담당자가 띄워놓은 servlet의 경우
1. Http헤더, 호출 정보, body, url 가져다가 호출함
2. responseBody를 byte[].class로 변환
3. ObjectMapper로 byte[] → ObjectNode 변환
4. 변환 실패 시 new String(byteArr) 값을 data :  “바이트~~” 로 pub


### 문제점

new String(byteArr) 의 경우 defaultCharset을 UTF- 8로 지정하는 것 같음
딥서치의 경우 ISO_8859_1 로 줌
그래서 Api에서  Kafka로 pub 할 때 new String(byteArr,StandardCharset.ISO_8859_1)로 주고
받을 때 string.getBytes(StandardCharsets.ISO_8859_1)로 받아야 함.

### API에서 UTF-8로 변환 불가

왜냐하면 딥서치에서 넘어올 때 gzip으로 압축해서 넘어오는중

```lua
    @Bean
    WebClient.Builder deepsearchWebClientBuilder() {
        SslContext build;
        try {
            build = SslContextBuilder.forClient().trustManager(InsecureTrustManagerFactory.INSTANCE)
                    .build();
        } catch (SSLException e) {
            throw new RuntimeException(e);
        }

        HttpClient httpClient = HttpClient.create().secure(t -> t.sslContext(build));

        return WebClient.builder()
                .clientConnector(new ReactorClientHttpConnector(httpClient))
                .exchangeStrategies(ExchangeStrategies.builder()
                        .codecs(configurer -> configurer.defaultCodecs().maxInMemorySize(-1))
                        .build())
                .defaultHeaders(httpHeaders -> {
                    httpHeaders.setBasicAuth("kbank", "kbank1");
                    httpHeaders.set("Accept-Encoding","gzip, deflate, br");
                });
    }
```

웹클라이언트 구성을 다음과 같이 하지 않는 경우(accept-encoding에 gzip) 5메가가 넘는 파일이 와버림. → Kafka 용량 초과

[[KAFKA-4169] Calculation of message size is too conservative for compressed messages - ASF JIRA](https://issues.apache.org/jira/browse/KAFKA-4169)


### 현재 MSA-API 호출 흐름

1. pod 에서 kafka로 pub 시 kafka message에 ("Accept-Encoding","gzip, deflate, br"); 넣어서 보냄
2. kafka의 메세지를 api가 받아서 헤더 값 포함해서 그대로 대외로 보냄
3. Accept-Encoding이 gzip이므로 대외에서는 gzip으로 압축된 결과값을 줌
4. api에서 byteArr[] 로 받아서 ObjectMapper의 ObjectNode로 변환 시도
  - →gzip으로 인코딩 되어있으므로 실패
5. 성공 시 json으로 pub, 실패 시 new String(byteArr[])으로 pub
  - → 여기서 new String 시 Charset을 ISO_8859_1로 지정해야하지만 우리만 쓰는게 아니라 전행 공통이라 defaultCharset으로 인코딩함 → 깨짐
6. 뭔가 인코딩이 두 번 된 문자열이 pod로 넘어옴(대외에서 ISO_8859_1 + gzip으로 한 번 압축된걸 내부 api가 UTF-8로 한번 더 인코딩)
7. 파싱 실패


## 원인

api 담당자가 들어오는 파일을 json으로 파싱해서 던져주면 된다는 생각만 하였기 때문.
위와 같이 json으로 의도를 하였지만 압축하여서 들어오는 경우를 생각하지 못함
추가로 위와 같은 문제의 경우 json이 아닌 경우(xml이나 csv 형식 등 파일)는 어떻게 할 예정인지 물어봤는데, 아직 정해진건 없다고 함(요건이 json만 있었나봄)

## 20240718 해결

결론 :  우리가 헤더에 Accept-Type을 넣지 않고 api 쪽에서 kafka message pub을 할 때 gzip 방식으로 압축해서 주기로 함


## 우려점 및 의문

1. api가 대외에서 내부로 bypass가 아니라 특정 로직으로 중간에 데이터를 바꾸는 경우에 대한 문제
  - 극단적으로는 hex값을 그냥 넘겨줘도 되는데..
  1. 물론 json으로 받은 응답을 자바에서 ObjectNode로 변환해서 response를 주면 결국에는 Json으로 넘기니 문제없는것 아니냐? 라고 물어볼 수 있는데 중간에 값이 한 번 변조되기때문에(예를 들어 인코딩이 바뀔 수도 있고) 바이트정보를 그대로 주지 않는 이상 어디서 문제가 생겼는지 한 번 더 확인해야하는 번거로움
  2. 대외 담당자가 왜 중간에서 
2. 단일 실패지점
  1. 아직 카프카에 대해 다루는게 케이뱅크에서는 최초이기 때문에 트래픽 제어를 어떻게 할까
  2. 여러 업무에서(계정계,카드계,가상자산,정보계,우리 등등…) 대외로 연동되는 openApi 솔루션을 찌름.
  3. 토픽 까봤는데 파티션 하나이기 때문에 인스턴스도 하나일것같음
  4. 이거 죽으면 끝나. Dbridge(상용솔루션)은 죽지 않겠지만 이번에 만든 서블릿은 높은 확률로 죽음. 그러면 kafka로 데이터 요청하던 업무들은 모두 영향감.
  - ⇒ 인스턴스 다중으로 띄워주세요. 파티션 지금 하나잖아요.
3. Lag에 대한 문제 + 상대 기관과 api 스펙 차이
  1. 밑에 그림에서

![](https://prod-files-secure.s3.us-west-2.amazonaws.com/c38aebd7-2834-4fac-b2fc-a2f0c17ce81d/1531cb8f-d046-4b14-835d-b8d2be1e66ca/image.png)

  2. 대외 구간을 엄밀히 뜯어보면 아래와같음

![](https://prod-files-secure.s3.us-west-2.amazonaws.com/c38aebd7-2834-4fac-b2fc-a2f0c17ce81d/b4e9b859-b83a-41ba-ab68-a6bc9756511c/image.png)

    - Dbridge는 솔루션이니깐 그렇다 치더라도 consumer는 이번에 띄우는건데 가용성을 신뢰할 수 없음 + 후처리하는 로직이 완벽하지 않음
      - 팩트) 딥서치 CP보다 케이뱅크 대외 OpenApi 솔루션 CP가 월등히 좋은건 사실
      - 그러므로 이런식으로 문제가 생김
    1. 딥서치를 호출해야하는 N개의 업무가 요청토픽에 열심히 pub함
    2. 딥서치 또는 오픈api가 약간 시원찮아서(커넥션풀이 부족해서) lag가 점점 생김
    3. 딥서치에서 응답을 안주는 경우
      1. Dbridge에서 계속 호출을 넘김 ⇒ 딥서치 서버 터짐
      2. Topic 실패하는 경우 최대 3번 호출함 ⇒ 더 터짐
    4. Dbridge에서 다른 업무들에 의해 커넥션 풀이 부족하여 내부 호출 큐가 쌓이는 경우
      1. Dbridge 병목이 해소되면 내부 호출 큐에 있는 딥서치 타겟 레코드를 꺼내다가 딥서치에 그대로 쏴버림
      2. 3번 현상으로 감
      3. 현재 tps 10으로 예상하고 Thread.sleep(100)을 걸어놓은 Pub job들은(솔직히 이것도 마음에 안듬. 대외로 나가기 위해 특정 솔루션에 의존하는 코드를 넣어놨는데 이런 기능도 없다면..) 토픽에 10tps를 쐈을 뿐이지 Dbridge가 10tps로 쏜다는 보장이 사라짐.
    - 위와 같은 현상을 예상하고 질문함 : **혹시 타겟지(ip주소도 상관없고, 도메인네임으로 분류해도 상관없고) 별로 tps를 제어할 수 있는 방법이 솔루션이나 consumer에 있나요? **
      - **⇒ 없다고 함…**
    - 결국 4-c,3-a 에서 말했던 것 처럼 업무에서 10Tps로 호출해도 상황에 따라 바깥 서버를 터뜨릴 수 있음
    - 기존 EAI-openApi를 통해 커넥션이 보장되던 방법에서는 소스코드단에서 TPS를 조절할 수 있었지만 kafka에서는 불가.
    - ⇒ 해당 기능 개발 필요할듯, 아니면 다른 좋은 방법 찾아봐야함
      - + 당분간 운영에서 상대기관 장애 날 수 있기도 해서 말씀드렸더니(자세하게는 말 안했고) 케이뱅크용 api 서버 증설했다고 함 ㅋㅋ


