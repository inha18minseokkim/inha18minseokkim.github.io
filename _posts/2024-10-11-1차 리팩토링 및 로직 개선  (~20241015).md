---
title: 1차 리팩토링 및 로직 개선 (~20241015)
date: 2024-10-11
tags:
  - Kafka
  - KEDA
  - 주식서비스
  - 개발
category:
  - 실무경험
  - 투자홈
---

투자홈 데이터 수신 파이프라인 안정화를 위한 1차 리팩토링 작업 내용 정리.

---

### 1. Kafka Consumer LAG 해소 — 파티션·인스턴스 수 확장 (1 → 3)

Kafka → RDB 적재 과정에서 특정 토픽들의 LAG가 지속적으로 누적되는 현상이 발생했다. 해당 토픽들은 데이터 변환 로직이 복잡하거나 적재 대상 레코드 수가 많아 단일 consumer로는 처리 속도가 수신 속도를 따라가지 못하는 상황이었다.

- **조치**: 해당 토픽의 파티션 수를 1 → 3으로 늘리고, consumer 인스턴스 수도 동일하게 증설하여 병렬 처리 가능하도록 변경.
- **효과**: LAG가 더 이상 누적되지 않고 실시간에 가깝게 소진됨.

---

### 2. 딥서치 API 교체 — 문제 있는 엔드포인트 → 신규 API

운영 중 딥서치 측의 특정 API에서 응답 지연 또는 오류가 반복적으로 발생했다. 딥서치 측에 문제를 공유하고, 대응책으로 신규 개발된 API 엔드포인트를 제공받아 교체 적용했다.

- 기존 API의 안정성 문제(응답 불능, 간헐적 오류 등)가 해소됨.
- 이후 동일 문제 재발 시 신속히 교체 요청할 수 있도록 연락 채널 정비.

---

### 3. Argo Workflow 로깅 개선 — 5분 주기 작업 모니터링

Argo Workflow에서 5분마다 실행되는 작업의 로그가 워크플로우 구조 특성상 확인하기 불편했다. 실행 이력이 짧게 유지되거나 로그가 분산되어 장애 발생 시 원인 파악이 어려운 상황이었다.

- **조치**: 워크플로우 YAML 로직을 수정하여 로그 집중 및 식별이 용이하도록 개선.
- 정상/오류 실행 여부를 빠르게 파악할 수 있는 구조로 변경.

---

### 4. KEDA 적용 — 유휴 시간대 노드 자원 절약

데이터 수신 작업은 장중에만 집중되고, 장 마감 후에는 거의 트래픽이 없다. 그러나 기존에는 consumer pod가 항상 실행 중이어서 유휴 시간대에도 노드 자원을 점유하고 있었다.

- **조치**: KEDA(Kubernetes Event Driven Autoscaler)를 적용하여 Kafka LAG 기반으로 consumer pod를 자동 스케일 인/아웃.
- LAG가 없는 구간에는 pod를 0으로 축소, 수신량이 늘어나면 자동으로 확장.
- **효과**: 불필요한 노드 자원 점유 제거, 인프라 비용 절감.

---

### 5. 52주 최고·최저가 집계 방식 수정

기존 52주 최고·최저가 계산 로직에서 집계 기준 또는 범위 처리에 오류가 있었다. 주식 수 변동(액면분할, 유무상증자 등) 이후 가격 히스토리와의 정합성 문제, 또는 집계 윈도우 경계 처리 미흡이 원인으로 파악되어 수정했다.
