---
title: "S3 + logback 활용안"
date: 2025-07-29
tags: [미지정]
category: 기타
---

# 현재 검토중이었던 버전


![](attachment:e3bdb8d4-293d-4cff-b289-6271f4d6a702:image.png)


## Kafka문제

1. 불?필요한 TGW 거침
  - 현재 Kbank EKS 환경에서 사용할 수 있는 MSK 없음. Kafka를 사용하려면 IDC에 있는 Confluent Kafka를 사용 해야 함. 또 정보계는 별도의 AWS에 있기 때문에 EKS 파드가 pub > 정보계 AWS쪽에서 sub 하려면 TGW를 두 번 타야 함
2. db connection 보다는 사정이 낫지만 gateway에서 꼭 로깅을 위해서 카프카 연결을 유지해야하는지에 대한 의문

### MSK를 사용하면?

IDC에 있는 On-premise Confluent Kafka 대신 MSA 계정으로 MSK를 띄우면 TGW 를 한 번만 거쳐도 됨. 다른 AWS 계정의 MSK를 싸게 찌를 수 있는 방법이 있으면 더 좋음
그렇다 하더라도 MSK에 레코드를 쌓는것 보다 S3에 로그를 쌓는것이 더 싸고 좋아 보임.

# S3 사용안


![](attachment:a3ed7c79-85c8-4261-9b4a-1933abfabbb3:image.png)

gateway 프로젝트에 logback 구성해놓고 특정 로그 레벨 만들어서 해당 로그레벨은 s3 마운트한 위치에 로그 떨궈
해당 s3 에 있는 파일을 정보계 에서 파싱해서 아테나에 적재를 해
S3는 게이트웨이 엔드포인트 사용할 때 추가요금 없어서 비용적으로는 더 좋을듯
어플리케이션 입장에서도 카프카 IO가 없어서 부담이 덜하고?
[Amazon S3에 대한 게이트웨이 엔드포인트 - Amazon Virtual Private Cloud](https://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpc-endpoints-s3.html)

# SRE 제안


### 기존 안

spring application 에서 s3 연결해서 ex) logback.xml에 특정 포맷 로그는 s3 쪽에 떨구는 방식으로 검토했었음

```kotlin
<!-- Maven 예시 -->
<dependency>
    <groupId>com.github.siteflo</groupId>
    <artifactId>logback-s3-rolling-policy</artifactId>
    <version>1.7</version>
</dependency>
```


```kotlin
<appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>logs/myapp.log</file>
    <encoder>
        <pattern>[%d] %-8relative %22c{0} [%-5level] %msg%xEx{3}%n</pattern>
    </encoder>
    <rollingPolicy class="ch.qos.logback.core.rolling.S3TimeBasedRollingPolicy">
        <fileNamePattern>logs/myapp.%d{yyyy-MM-dd_HH-mm}.%i.log.gz</fileNamePattern>
        <awsAccessKey>ACCESS_KEY</awsAccessKey>
        <awsSecretKey>SECRET_KEY</awsSecretKey>
        <s3BucketName>myapp-logging</s3BucketName>
        <s3FolderName>log</s3FolderName>
        <rolloverOnExit>true</rolloverOnExit>
        <shutdownHookType>SERVLET_CONTEXT</shutdownHookType>
        <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
            <maxFileSize>10MB</maxFileSize>
        </timeBasedFileNamingAndTriggeringPolicy>
    </rollingPolicy>
</appender>
```

그런데 생각해보니깐 이것도 결국에 io임. s3를 마운트하여 sysout 하려고 했는데 예제가 죄다 본질적으로 multipart request를 사용하거나 특정 sdk를 사용하여 우리가 흔히 생각하는 파일시스템 방식으로 작동하는것이 아니었음.

### perplexity Q) **s3 저장소를 쿠버네티스 + 스프링 어플리케이션에 마운트하는 방법은 없는것?** 

AWS S3는 본질적으로 **오브젝트 스토리지**이며, 전통적인 파일시스템(POSIX)의 마운트 대상이 아닙니다. 그러나 쿠버네티스(Kubernetes)와 Spring Boot 애플리케이션 환경에서 S3를 "마치 마운트한 것처럼" 활용하는 방법과, 진짜로 S3 버킷을 쿠버네티스 파드에 마운트하는 현대적인 방법들이 있습니다.
[Mountpoint for Amazon S3로 EKS Pod에 S3 mount하기](https://mokpolar.tistory.com/74)
아무튼 마운트하는방식은 현대적? 이지 않기 때문에 기존 의도는 아닌듯하다
[Mountpoint for Amazon S3 CSI 드라이버를 통해 Amazon S3 객체에 액세스 - Amazon EKS](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/s3-csi.html)

### Mountpoint의 문제

edit이 안됨,, object storage이다 보니 특정 파일을 추가하는것은 되지만 해당 파일을 수정하는것은 불가,, 읽는것은 가능,, 블록기반 스토리지의 작동 의도를 무시하는 동작은 할 수 없는 듯 하다.
  - 만약 진짜로 edit을 구현한다면 통 파일을 갈아끼우는 방식으로 edit을 구현해야할텐데 끔찍하다

## 첫 번째 절충 안

[How to optimize log management for Amazon EKS with Amazon FSx for NetApp ONTAP | Amazon Web Services](https://aws.amazon.com/ko/blogs/containers/optimize-log-management-for-amazon-eks-with-amazon-fsx-for-netapp-ontap/)
를 참고하여

![](attachment:a8738eea-e494-4245-8967-19e2b10a0eec:image.png)

PVC를 구성하기로 하였음 EFS를 네임스페이스별로 따서 pod에서 마운트 시켜놓으면 거기서 logback으로 파일을 떨구는 구조
SRE쪽에서 반대함 사유 : 인력부족인데 볼륨 관리까지 힘듦
뭐..그럴수있다고 생각함

### 잠정결론 : sidecar 사용해서 stdout을 Fluentbit로 처리

기존에 이미 수집되고 있던 stdout 로그에서 Fluentbit로 필터링해서 빅데이터쪽 MSK로 쏘던지 S3로 마운트하던 해주겠다 함
