---
title: "EDB 성능 봐야함"
date: 2024-02-01
tags: [미지정]
category: 기타
---

기존 식품물가 - DB 몰빵형
kamis 상품코드(100,111,01,01,04) & 지역코드 여러개(수원,용인,의정부) join 케이뱅크 노출 지역(경기도) 이런식으로 한 다음 group by 날짜, 케이뱅크 노출지역 ⇒ 평균 도출한 값
  - 특정 kamis 상품의 특정 지역, 특정 시점의 일간,주간,월간,반기,연간 평균을 통계 테이블에 적재하고 해당 내용을 select 해서 보여줌
  - 내부상품코드(001 ↔ 100,111,01,01,04) 두 개 join 해서 보여줌
  - 배추같이 내부상품코드 하나에 kamis 상품 여러개가 매핑되어있는 경우 (내부상품 배추 ↔ 봄,고랭지,가을,월동 배추) 200,213,AL,01,04 이런식으로 매핑해놓음 → 모두 DB에서 함
To Be - 자바에 녹여냄
  - 특정 kamis 상품의 특정 지역, 특정 시점의 일간 평균을 통계 테이블에 적재 → 여기까지가 DB
  - 내부상품코드와 kamis 상품은 1 : N 관계
  - 대고객 보여줄 때는 내부상품코드를 select 한 다음 group by mean 가격을 하여 보여줌
  - 일간, 주간, 월간, 반기, 연간 통계 테이블을 미리 저장해놓지 않기 때문에 365일치 데이터를 가져와서 java에서 끊어서 group by mean으로 보여줌

Entity를 가지고 객체 간의 연관관계를 생각하므로 기존 방식보다 DB Connection pool 호출이 잦음
다만 persistent + redis cache로 성능을 가져간다


코드를 보면 일,주,월,반년,연간 데이터를 모두 호출 한번에 뿌려줌.
분리해서 호출하고싶지만
프론트 호출 로직을 바꿀 수 없기 때문에 어쩔 수 없이 한번에 조회해야함
SQL 플랜 봐야할 수도 + Redis Cache


```sql
select
            ip1_0.id,
            ip1_0.additional_description,
            ip1_0.inner_category_id,
            ip1_0.is_available,
            ip1_0.is_main_material,
            ip1_0.is_seasonal,
            ip1_0.order_sequence,
            ip1_0.product_name,
            ip1_0.season_end_date,
            ip1_0.season_start_date,
            ppi1_0.base_date,
            avg(ppi1_0.price)
        from
            user_group_code ugc1_0,
            user_code uc1_0,
            inner_product ip1_0
        join
            base_product bp1_0
                on bp1_0.inner_product_id=ip1_0.id
        left join
            processed_price_info ppi1_0
                on ppi1_0.base_product_id=bp1_0.id
        where
            ip1_0.is_available= true
            and (
                ppi1_0.base_date between '20240101' and '20240120'
                or ppi1_0.base_date is null
            )
            and (
                ppi1_0.base_range= 'DAY'
                or ppi1_0.base_range is null
            )
            and (
                ppi1_0.region_info_id=uc1_0.code_detail_name
                or ppi1_0.region_info_id is null
            )
            and ugc1_0.id= 'FDPREGN1101'
            and uc1_0.user_group_code_id= 'FDPREGN1101'
        group by
            ip1_0.id,
            ppi1_0.base_date
```


![](https://prod-files-secure.s3.us-west-2.amazonaws.com/c38aebd7-2834-4fac-b2fc-a2f0c17ce81d/34d7ae10-e462-497e-97f4-04a751b4cc95/Untitled.png)

일단 로컬은 파일 수가 적어서 얼마안되므로 캐싱만 수행

기존 식품물가와 비슷하게 인덱스 만들고 QT 플랜 보지만
캐싱으로 퍼포먼스 올릴 예정
  - +기존에는 api 별로 쿼리 분리해놨지만 이번에는 최대 두 가지 정도만 