---
title: DB Sync 개선 - 거래이력 로깅 병목 해결
date: 2025-07-29
tags:
  - Logging
  - MSA
  - Java
  - Kafka
  - 케이뱅크
  - Spring-Cloud
category:
  - 실무경험
  - MSA표준
---

정보보호 요건을 충족하기 위해 모든 API 요청/응답을 RDB에 저장하는 현재 구조의 문제점과 개선 방안을 정리한다.

---

## 현재 구조 (AS-IS)

API Gateway에서 들어오는 모든 요청에 대해 다음 정보를 RDB에 저장 중:
- MCI 서비스코드
- Input/Output 데이터
- 고객식별자

![현재 거래이력 저장 구조](/assets/images/Pasted%20image%2020260228171315_fee2b492.png)

---

## 문제점

| 문제 | 설명 |
|------|------|
| DB 커넥션 과다 | EDB에 커넥션이 과도하게 몰림 |
| 불필요한 의존성 | EDB를 사용하지 않는 서비스도 반드시 거쳐야 함 |
| 응답 지연 | Request → DB Insert → 서비스 처리 → DB Insert → Response (2회 블로킹) |

> **핵심 문제:** DB가 "수문장" 역할을 하면서 모든 요청이 2번씩 블로킹됨

---

## 최종 목표 (TO-BE)

Kafka 도입 후 거래이력을 Kafka에 Publish하고, 정보계에서 별도로 Subscribe하여 후처리하는 구조로 전환 예정.

단, Kafka 도입 시점이 불확실하여 우선 카드계 공통 테이블 로깅 방식을 차용해 정보보호 요건에 대응했다.

---

## 단기 개선안 (Kafka 도입 전)

Kafka 없이도 블로킹 문제를 완화할 수 있는 방법들:

| 방안 | 설명 | 비고 |
|------|------|------|
| **R2DBC** | 논블로킹 DB 처리 | 수신개발팀 사용 중. JPA 연관관계 불필요, 단순 Insert만 하면 됨 |
| **@Async** | 비동기 적재 | 스레드풀 관리 필요하나 간단. R2DBC보다 레퍼런스 풍부 |
| **Persistable** | save() 시 SELECT 제거 | JpaRepository의 불필요한 SELECT 방지 |

**권장 조합:** `R2DBC + Persistable` 또는 `@Async + Persistable`

---

## 한계점

위 방안을 적용하더라도 여전히 남는 문제:
- 스레드풀을 요청당 2회 사용 (Request/Response 각각)
- 로그 정보를 굳이 RDB에 유지해야 하는가?

---

## 관련 논의

로깅 방식 개선에 대한 추가 논의가 진행되었다:

- [S3 + Logback 활용안]({% post_url 2025-07-29-S3 + logback 활용안 %}) - Kafka, S3, Fluentbit를 활용한 로깅 방안 검토