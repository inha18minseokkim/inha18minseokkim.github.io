---
title: 25' Associate 미니 프로젝트 제출
date: 2025-11-06
tags:
  - 기획
  - AI/ML
  - 주식서비스
category:
  - 발표자료
---

| 항목 | 내용 |
|---|---|
| 소속부서 | 혁신서비스개발팀 |
| 주제 | 실시간 공시 정보 요약 알림 |

---

## 개요

### 배경 및 목적

투자 관련 제휴 데이터를 처리함에 있어서, 단순히 **가격 정보나 재무정보를 제공하는 방식**으로는 서비스 차별화가 어렵다. 외부에서 이미 가공된 데이터를 구매해 서비스하는 방법도 있지만, **비용 부담이 크고 내재화가 불가능**하여 **장기적인 리스크**가 존재한다.

이에 따라 **내부에서 가공 가능한 의미 있는 데이터**로 주목한 것이 바로 **공시 데이터**다. 공시 데이터는 기업의 주요 의사결정 및 재무 현황이 포함된 정보로, 투자 의사결정에 있어 가장 유의미한 데이터 중 하나다. 하지만 공시 데이터는 **정형화되지 않은 다양한 형태의 보고서(사업보고서, 변경신고서 등)** 로 존재하며, 각 문서의 형식이 제각각이라 **일관된 방식으로 제공하기 어렵다.**

현재 시중 서비스들은 아래와 같이 **단순 웹뷰 형태로 공시 데이터를 노출**하는 수준에 머물러 있다.

![이미지](/assets/images/Pasted%20image%2020260227174522.png)

*타사 사례: 카카오페이증권 공시 보기*

### 기대효과

본 프로젝트의 목적은, 공시가 등록되었을 때 **정형화된 HTML 문서를 그대로 보여주는 대신**, **요약된 자연어 형태로 공시 내용을 전달**하여 사용자가 **빠르고 쉽게 핵심 정보를 파악**할 수 있도록 하는 것이다.

---

## 데이터 및 방법론

### 사용 데이터

금융감독원 전자공시시스템(DART) 데이터 — 무료 오픈 API 제공

![이미지](/assets/images/Pasted%20image%2020260227174528.png)

**주요 특징:**
1. XML 형태로 제공
2. euc-kr, utf-8 등 법인마다 인코딩 방식이 다양함
3. 표, 다단, 줄글, CSS 등 여러 유형의 데이터가 복잡하게 혼재
4. 문서 길이가 1페이지부터 수십 페이지까지 다양

---

## 접근 방법

### 알고리즘 및 모델

1. **문서 전처리**
   - Python의 `lxml`을 사용해 불필요한 태그 제거 및 본문 평탄화 수행.
   - 텍스트만 남기고 HTML 구조와 CSS 스타일 제거.

2. **문서 청킹 및 벡터 저장**
   - 긴 문서를 청킹하여 Vector DB에 저장.
   - 유사한 문서 Chunk N개를 검색한 뒤, LLM이 해당 내용을 종합 요약.

   ```python
   fields = [
       FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=50),
       FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=5000),
       FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
       FieldSchema(name="metadata", dtype=DataType.JSON)
   ]
   schema = CollectionSchema(fields, description="공시문서 파싱결과")
   ```

3. **검색 및 원문 추적**
   - `Milvus` Vector DB에 **(종목코드, 원본문서명, 벡터)** 쌍으로 저장.
   - 요약 결과에서 흥미로운 내용이 있을 경우, 사용자가 원문 출처를 바로 확인 가능.

4. **컨텍스트 유지**
   - LangChain의 **Chunking 기법**을 활용해 긴 문서의 맥락을 유지하며 요약 품질 확보.

### 분석 절차

1. **공시 문서 수집**: 종목코드를 입력해 DART Open API를 통해 해당 문서 다운로드 및 적재.
2. **전처리**: `lxml`과 Python을 이용해 불필요한 태그 제거, 텍스트 정제.
3. **문서 분할**: LangChain의 `RecursiveCharacterTextSplitter`를 이용하여 문서를 적절한 크기로 분할.
4. **임베딩 생성**: OpenAI 임베딩 모델을 활용해 각 텍스트를 벡터로 변환.
5. **벡터 DB 적재**: 임베딩 결과를 스키마 기반으로 Milvus에 저장.
6. **유사 구간 검색**: "공시정보", "소유상황변동" 등 키워드 기반으로 유사 문서 N개 검색.
7. **LLM 요약 수행**: 검색된 문서 조각을 LLM 프롬프트에 입력하여 요약 결과 생성.

---

## 결과 요약

![이미지](/assets/images/Pasted%20image%2020260227174533.png)

---

## 한계점 및 향후 개선 방향

### 한계점

- **환경 제약**: 공중망에서 파이프라인을 개발했으나, 클라우드 환경(SageMaker) 적용 시 연결 문제가 발생하여 공중망 기반 프로젝트를 그대로 제출했다.
- **데이터 출처 단일화**: 현재 금융감독원 데이터만 활용 중으로, 다양한 출처 확보가 필요하다.
- **컴플라이언스 로직 미흡**: 투자 유의 문구, 리스크 안내 등 관련 규제 준수 로직이 부족하다.
- **벡터 데이터 노이즈**: 불필요한 텍스트까지 벡터 DB에 포함되어 검색 품질이 저하될 가능성이 있다.
- **의미 손실**: 태그 제거 과정에서 표나 다단 형식에 담긴 의미가 일부 누락된다.

### 개선 아이디어

- **Faiss 기반 경량화 구조 도입**
  - 현재는 모든 공시 데이터를 Milvus에 저장해 쿼리 시 유사 문서를 찾아 요약하는 방식이다.
  - Faiss를 사용해 **특정 공시 문서 단위로 요약을 수행한 뒤 결과만 저장**하고 메모리를 즉시 해제하는 방식이 시스템 구조상 더 효율적으로 판단된다. 대고객에게는 요약 결과만 노출하는 방식으로 전환 가능.

- **뉴스 데이터 연계**
  - 공시 데이터와 **해당 시점의 관련 뉴스 기사**를 함께 수집하면, 단순 요약을 넘어 **맥락 있는 분석 및 주변 정보 제공**이 가능해진다.

- **가드레일 프롬프트 적용**
  - 투자 권유, 과도한 기대를 유발할 수 있는 문구를 자동 필터링하는 **안전 프롬프트 로직** 추가가 필요하다. 이를 통해 **컴플라이언스 리스크를 최소화**할 수 있다.
