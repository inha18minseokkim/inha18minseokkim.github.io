---
title: "AWS re:Invent Las Vegas 2025 참관 후기"
date: 2025-12-01
tags: [AWS, 컨퍼런스, 클라우드, AI, 케이뱅크]
---

회사 사내 AI 아이디어 공모전 금상 포상으로 상금 400만원과 함께 AWS re:Invent Las Vegas 참가 기회를 얻었다. 들은 세션들 간략 정리.

## 세션 목록

### 월요일

| 세션                                                                     | 주요 내용            |
| ---------------------------------------------------------------------- | ---------------- |
| Telemetry Forensics: Debugging event streams with metrics & traces     | 이벤트 스트림 디버깅 방법론  |
| Optimizing agentic AI apps with semantic caching in Amazon ElastiCache | AI 에이전트 앱 성능 최적화 |
| Evaluating architectural trade-offs: Cloud patterns for flexibility    | 클라우드 아키텍처 트레이드오프 |
| Behind the scenes: How AWS drives operational excellence & reliability | AWS 운영 안정성       |
| Supercharge Lambda functions for security and performance              | Lambda 성능/보안     |
| Vibe data modeling with Amazon DynamoDB                                | DynamoDB 데이터 모델링 |

### 화요일

| 세션 | 주요 내용 |
|------|---------|
| Developing Unit Cost Metrics with Cloud Intelligence Dashboards | 클라우드 비용 메트릭 |
| Inference on AWS Trainium and Amazon EKS using vLLM | Trainium + vLLM 추론 |
| Low-cost logging and observability with Amazon OpenSearch Service | OpenSearch 관측성 |

### 수요일

| 세션 | 주요 내용 |
|------|---------|
| Advanced data modeling for Amazon ElastiCache | ElastiCache 고급 데이터 모델링 |
| Building on AWS resilience: Innovations for critical success | AWS 탄력성 패턴 |
| Building resilient deployment pipelines with Amazon ECS | ECS 배포 파이프라인 |

### 목요일

| 세션 | 주요 내용 |
|------|---------|
| Mastering Fluent-bit: Performance at Scale | Fluent-bit 대규모 로그 처리 |
| Building the Future Trading Platform leveraging AI and AWS | AI 기반 거래 플랫폼 |
| Lambda Managed Instances: EC2 Power with Serverless Simplicity | Lambda + EC2 하이브리드 |

---

## 인상 깊었던 세션들

### Semantic Caching for AI Apps (ElastiCache)

AI 에이전트 앱에서 동일하거나 유사한 질문이 반복될 때, 매번 LLM을 호출하는 대신 임베딩 유사도 기반으로 캐시 히트를 판단하는 기법. 토큰 비용과 레이턴시 모두 줄일 수 있다.

케이뱅크 주식 챗봇에서도 "삼성전자 주가 알려줘" 같은 반복 질문에 활용할 수 있을 것 같다.

### Inference on Trainium + vLLM

AWS Trainium은 NVIDIA GPU 대비 가격 효율이 높다는 걸 강조. vLLM과 EKS를 조합해서 대규모 추론 서비스를 운영하는 패턴. H100 부하테스트를 해봤던 경험이 있어서 비교하면서 들을 수 있었다.

### Building the Future Trading Platform with AI

금융 거래 플랫폼에 AI를 적용하는 아키텍처 사례. 케이뱅크 주식 서비스와 유사한 도메인이라 집중해서 들었다. 실시간 데이터와 AI 추론을 결합하는 방식에서 우리 시스템과 비교하며 고민할 점들이 많았다.

---

## 총평

재인벤트는 규모가 어마어마하다. 세션만 수백 개고 expo 공간도 거대하다. 클라우드 트렌드의 방향이 AI 인프라로 완전히 쏠려 있다는 걸 체감했다.

업무에서 직접 경험했던 것들(vLLM, EKS, ElastiCache, Kafka)을 AWS 공식 세션에서 심화 내용으로 들으니까 훨씬 잘 이해되었다. 공모전 준비하면서 쌓은 경험이 여기까지 연결된 느낌.
